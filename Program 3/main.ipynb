{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alejo Vinluan\n",
    "abv210001\n",
    "CS 4395.002\n",
    "\n",
    "# WordNet Basics\n",
    "\n",
    "## Overview\n",
    "WordNet is a network and organizational tactic of all words including nouns, verbs, adjectives, and adverbs. For every word in the network, WordNet lists short definitions, synonyms, usage, and relations to other words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1129)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Demonstration with a Noun\n",
    "In this excercise, the noun \"wizard\" will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun = \"wizard\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the synsets for \"wizard\" will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synsets for `wizard`:\n",
      "\t- ace\n",
      "\t- sorcerer\n",
      "\t- charming\n"
     ]
    }
   ],
   "source": [
    "synsets = nltk.corpus.wordnet.synsets(noun)\n",
    "print(\"Synsets for `wizard`:\")\n",
    "for synset in synsets:\n",
    "    print(\"\\t-\", synset.name().split('.')[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chunk of code will select 1 synset from the list (at random). Then, the code will will extract the definition, usage examples, and lemmas from the sysnset. Finally, the code will traverse up the hierarchy of synsets, outputting them while traversing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Synset derived from 'Wizard': sorcerer \n",
      "\n",
      "Definition: one who practices magic or sorcery \n",
      "\n",
      "No examples found.\n",
      "\n",
      "Lemmas:\n",
      "\t-  sorcerer\n",
      "\t-  magician\n",
      "\t-  wizard\n",
      "\t-  necromancer\n",
      "\t-  thaumaturge\n",
      "\t-  thaumaturgist\n",
      "\n",
      "Traversing up the hierarchy for: sorcerer\n",
      "\t- occultist\n",
      "\t- person\n",
      "\t- causal_agent\n",
      "\t- physical_entity\n",
      "\t- entity\n"
     ]
    }
   ],
   "source": [
    "# Importing random to randomly select a synset from noun\n",
    "import random\n",
    "\n",
    "# Setting a seed to reproduce results for testing\n",
    "random.seed(1234)\n",
    "\n",
    "# Choose a synset\n",
    "random_synset = random.choice(synsets)\n",
    "\n",
    "# Print which synset was randomly selected\n",
    "print(\"Random Synset derived from 'Wizard':\", random_synset.name().split('.')[0], \"\\n\")\n",
    "\n",
    "# Print the definition of the randomly selected synset\n",
    "print(\"Definition:\", random_synset.definition(), \"\\n\")\n",
    "\n",
    "# Print usage examples if they exist\n",
    "if len(random_synset.examples()) == 0:\n",
    "    print(\"No examples found.\\n\")\n",
    "else:\n",
    "    print(\"Usage examples:\")\n",
    "    for example in random_synset.examples():\n",
    "        print(\"\\t- \", example)\n",
    "        \n",
    "# Print lemmas if they exist\n",
    "if len(random_synset.lemmas()) == 0:\n",
    "    print(\"No lemmas found.\\n\")\n",
    "else:\n",
    "    print(\"Lemmas:\")\n",
    "    for lemma in random_synset.lemmas():\n",
    "        print(\"\\t- \", lemma.name().split('.')[0])\n",
    "    \n",
    "# Traversing the hierarchy\n",
    "# Find whether the current synset has a hypernym\n",
    "if len(random_synset.hypernyms()) > 0:\n",
    "    # Begin traversing the hierarchy\n",
    "    print(\"\\nTraversing up the hierarchy for:\", random_synset.name().split('.')[0])\n",
    "    # Select the first hypernym for the given synset\n",
    "    hypernym = random_synset.hypernyms()[0]\n",
    "    # Continue looping while hypernyms are available\n",
    "    while hypernym:\n",
    "        print(\"\\t-\", hypernym.name().split('.')[0])\n",
    "        # Update the hypernym to the current synset's hypernym. Unless the hypernym is\n",
    "        #  the top of the synset list, which is entity.\n",
    "        if len(hypernym.hypernyms()) > 0 and hypernym.name() != \"entity.n.01\":\n",
    "            hypernym = hypernym.hypernyms()[0]\n",
    "        else:\n",
    "            break\n",
    "else:\n",
    "    print('No hypernyms found for synset:', random_synset.name().split('.')[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When traversing up the WordNet hierarchy, WordNet will go from specific to broad examples. Sorcerer's hypernym is 'occultist', which is defined as somebody who practices magic, astrology, alchemy, or other supernatural powers. This implies that all sorcerers are occultists, but not all occultists are sorcerers. The same can be said from occultists to person. A person is an incredibly broad category that can encapsulate all occultists, but is not necesarilly an occultist. Eventually, the hypernyms turn into an entity, which can represent anything.\n",
    "\n",
    "From the randomly selected synset, here is a list of it's hypernyms, hyponyms, meronyms, holonyms, and antonyms if they're available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypernyms:\n",
      "\t- occultist\n",
      "Hyponyms:\n",
      "\t- enchanter\n",
      "\t- exorcist\n",
      "\t- magus\n",
      "\t- sorceress\n",
      "\t- witch_doctor\n",
      "\n",
      "Found no meronyms for: sorcerer \n",
      "\n",
      "Found no antonyms for: sorcerer \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print hypernyms\n",
    "if len(random_synset.hypernyms()) > 0:\n",
    "    print(\"Hypernyms:\")\n",
    "    for hypernym in random_synset.hypernyms():\n",
    "        print(\"\\t-\", hypernym.name().split('.')[0])\n",
    "else:\n",
    "    print(\"Found no hypernyms for\", random_synset.name().split('.')[0], \"\\n\")\n",
    "    \n",
    "# Print hyponyms\n",
    "if len(random_synset.hyponyms()) > 0:\n",
    "    print(\"Hyponyms:\")\n",
    "    for hyponym in random_synset.hyponyms():\n",
    "        print(\"\\t-\", hyponym.name().split('.')[0])\n",
    "else:\n",
    "    print(\"Found no hyponyms for\", random_synset.name().split('.')[0], \"\\n\")\n",
    "    \n",
    "# Print meronyms\n",
    "if len(random_synset.part_meronyms()) > 0:\n",
    "    print(\"Meronyms:\")\n",
    "    for meronym in random_synset.part_meronyms():\n",
    "        print(\"\\t-\", meronym.name().split('.')[0])\n",
    "else:\n",
    "    print(\"\\nFound no meronyms for:\", random_synset.name().split('.')[0], \"\\n\")\n",
    "    \n",
    "# Print antonyms\n",
    "if len(random_synset.lemmas()) > 0 and len(random_synset.lemmas()[0].antonyms()) > 0:\n",
    "    print(\"Antonyms:\")\n",
    "    for antonym in random_synset.lemmas()[0].antonyms():\n",
    "        print(\"\\t-\", antonym.name().split('.')[0])\n",
    "else:\n",
    "    print(\"Found no antonyms for:\", random_synset.name().split('.')[0], \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Demonstration with a Verb\n",
    "The verb \"hypnotize\" will be used. \n",
    "\n",
    "The following code chunk will output all synsets for \"bewitch\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synsets for `bewitch`: \n",
      "\t- capture\n",
      "\t- magnetize\n",
      "\t- hex\n"
     ]
    }
   ],
   "source": [
    "verb = \"bewitch\"\n",
    "synsets = nltk.corpus.wordnet.synsets(verb)\n",
    "print(\"Synsets for `bewitch`: \")\n",
    "for synset in synsets:\n",
    "    print(\"\\t-\", synset.name().split('.')[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From \"bewitch\", a random synset will be chosen. The definition, usage examples, and lemmas will be printed. Finally, the code will traverse up synset hierarchy and output at each level of the hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Synset derived from 'Bewitch': capture \n",
      "\n",
      "Definition: attract; cause to be enamored \n",
      "\n",
      "Usage examples:\n",
      "\t-  She captured all the men's hearts\n",
      "Lemmas:\n",
      "\t-  capture\n",
      "\t-  enamour\n",
      "\t-  trance\n",
      "\t-  catch\n",
      "\t-  becharm\n",
      "\t-  enamor\n",
      "\t-  captivate\n",
      "\t-  beguile\n",
      "\t-  charm\n",
      "\t-  fascinate\n",
      "\t-  bewitch\n",
      "\t-  entrance\n",
      "\t-  enchant\n",
      "\n",
      "Traversing up the hierarchy for: capture\n",
      "\t- attract\n"
     ]
    }
   ],
   "source": [
    "# Choose a synset\n",
    "random_synset = random.choice(synsets)\n",
    "\n",
    "# Print which synset was randomly selected\n",
    "print(\"Random Synset derived from 'Bewitch':\", random_synset.name().split('.')[0], \"\\n\")\n",
    "\n",
    "# Print the definition of the randomly selected synset\n",
    "print(\"Definition:\", random_synset.definition(), \"\\n\")\n",
    "\n",
    "# Print usage examples if they exist\n",
    "if len(random_synset.examples()) == 0:\n",
    "    print(\"No examples found.\\n\")\n",
    "else:\n",
    "    print(\"Usage examples:\")\n",
    "    for example in random_synset.examples():\n",
    "        print(\"\\t- \", example)\n",
    "        \n",
    "# Print lemmas if they exist\n",
    "if len(random_synset.lemmas()) == 0:\n",
    "    print(\"No lemmas found.\\n\")\n",
    "else:\n",
    "    print(\"Lemmas:\")\n",
    "    for lemma in random_synset.lemmas():\n",
    "        print(\"\\t- \", lemma.name().split('.')[0])\n",
    "    \n",
    "# Traversing the hierarchy\n",
    "# Find whether the current synset has a hypernym\n",
    "if len(random_synset.hypernyms()) > 0:\n",
    "    # Begin traversing the hierarchy\n",
    "    print(\"\\nTraversing up the hierarchy for:\", random_synset.name().split('.')[0])\n",
    "    # Select the first hypernym for the given synset\n",
    "    hypernym = random_synset.hypernyms()[0]\n",
    "    # Continue looping while hypernyms are available\n",
    "    while hypernym:\n",
    "        print(\"\\t-\", hypernym.name().split('.')[0])\n",
    "        # Update the hypernym to the current synset's hypernym. Unless the hypernym is\n",
    "        #  the top of the synset list, which is entity.\n",
    "        if len(hypernym.hypernyms()) > 0:\n",
    "            hypernym = hypernym.hypernyms()[0]\n",
    "        else:\n",
    "            break\n",
    "else:\n",
    "    print('No hypernyms found for synset:', random_synset.name().split('.')[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the verb hierarchy continues to present verbs that are broader than the currently selected verb. However, there is no top level for these verbs like \"entity\" is for nouns. The verbs that are broader may not also mean the same as the more specific verb. For example, attract and capture are not interchangeable. Although capture can mean attract in some ways.\n",
    "\n",
    "## Morphy Demonstration\n",
    "The following code block will find different forms of the verb 'casting'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cast\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "print(wordnet.morphy('casting',wordnet.VERB))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this instance there was only one word Morphy found for 'casting': cast. \n",
    "\n",
    "## Wu-Palmer Simlarity Metric and Lesk Algorithm\n",
    "The following code block will utilize the Wu-Palmer Similarity Metric and Lesk Algorithm to find how similar the words 'Sorcerer' and 'Alchemist' are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "sorcerer = nltk.corpus.wordnet.synsets('sorcerer')[0]\n",
    "alchemist = nltk.corpus.wordnet.synsets('alchemist')[0]\n",
    "\n",
    "wup_score = wordnet.synset(sorcerer.name()).wup_similarity(wordnet.synset(alchemist.name()))\n",
    "print(wup_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('sorcerer.n.01')\n",
      "Synset('alchemist.n.01')\n",
      "Synset('sorcerer.n.01')\n",
      "Synset('alchemist.n.01')\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "\n",
    "sample_sentence = ['The', 'sorcerer', 'casted', 'a', 'spell', '.']\n",
    "print(lesk(sample_sentence, 'sorcerer', 'n'))\n",
    "\n",
    "sample_sentence = ['The', 'alchemist', 'brewed', 'a', 'potion', '.']\n",
    "print(lesk(sample_sentence, 'alchemist', \"n\"))\n",
    "\n",
    "sample_sentence = ['The', 'sorcerer', 'casted', 'a', 'spell', 'against', 'the', 'alchemist', '.']\n",
    "print(lesk(sample_sentence, 'sorcerer', 'n'))\n",
    "print(lesk(sample_sentence, 'alchemist', 'n'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Wu-Palmer Similarity Metric finds that 'sorcerer' and 'alchemist' have a 66% similarity metric. However, after using Lesk, there were no similarities found. This may be because there is no ambiguity between 'sorcerer' and 'algorithm'. A better metric would be using the word 'bank' since that could be used to differentiate between a bank account, a river bank, or a slope bank.\n",
    "\n",
    "## SentiWordNet\n",
    "SentiWordNet is built on WordNet and can give words a score of positive, negative, or objective. This can be useful since a program can breakdown the sentiment of sentences or pages. For example, when scraping the Wikipedia page for \"Disneyland\", the program can find a positive sentiment towards Disneyland and understand that Disneyland is generally seen as positive.\n",
    "\n",
    "The following code will utilize the emotionally charged word 'fear', find it's senti-synsets, and output the polarity scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Score: 0.125\n",
      "Negative Score: 0.625\n",
      "Objective Score: 0.25\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "senti_synset = swn.senti_synset('fear.v.01')\n",
    "print(senti_synset)\n",
    "\n",
    "print(\"Positive Score:\", senti_synset.pos_score())\n",
    "print(\"Negative Score:\", senti_synset.neg_score())\n",
    "print(\"Objective Score:\", senti_synset.obj_score())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next example will find the sentiment score of the sentence, \"I absolutely love getting scared by Haunted Houses.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<iodine.n.01: PosScore=0.0 NegScore=0.0>\n",
      "<absolutely.r.01: PosScore=0.5 NegScore=0.0>\n",
      "<love.n.01: PosScore=0.625 NegScore=0.0>\n",
      "<acquiring.n.01: PosScore=0.0 NegScore=0.0>\n",
      "<frighten.v.01: PosScore=0.375 NegScore=0.0>\n",
      "<by.r.01: PosScore=0.0 NegScore=0.0>\n",
      "<haunt.v.01: PosScore=0.0 NegScore=0.0>\n",
      "<house.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive Score: 1.5\n",
      "Negative Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "sentence = 'I absolutely love getting scared by Haunted Houses'\n",
    "positive_score = 0\n",
    "negative_score = 0\n",
    "\n",
    "tokens = sentence.split()\n",
    "for token in tokens:\n",
    "    syn_list = list(swn.senti_synsets(token))\n",
    "    if syn_list:\n",
    "        syn = syn_list[0]\n",
    "        negative_score += syn.neg_score()\n",
    "        positive_score += syn.pos_score()\n",
    "\n",
    "print(\"Positive Score:\", positive_score)\n",
    "print(\"Negative Score:\", negative_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am surprised that there is a 0 in negative score after utilizing the word \"scared\", which turned into a Synset of \"frightened\". I suspect that WordNet may have utilized the context of the sentence as a whole to determine the sentiment of the entire sentence. Knowing these scores is important to breakdown how to handle and process certain emotionally charged statements within Natural Language Processing.\n",
    "\n",
    "## Collocations\n",
    "Collacations are words that are generally put together, but do not make literal sense. They are together often enough that the meaning is understood, but either word cannot be replaced by a synonym to get the same meaning. Some examples of collocations include \"heavy rain\" and \"high school\".\n",
    "\n",
    "The following code block will output collocations for The Inaugural Corpus. Then, it will select one coallocation, and calculate mutual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collocation List: [('United', 'States'), ('fellow', 'citizens'), ('years', 'ago'), ('four', 'years'), ('Federal', 'Government'), ('General', 'Government'), ('American', 'people'), ('Vice', 'President'), ('God', 'bless'), ('Chief', 'Justice'), ('one', 'another'), ('fellow', 'Americans'), ('Old', 'World'), ('Almighty', 'God'), ('Fellow', 'citizens'), ('Chief', 'Magistrate'), ('every', 'citizen'), ('Indian', 'tribes'), ('public', 'debt'), ('foreign', 'nations')] \n",
      "\n",
      "Random Collocation: ('Chief', 'Justice') \n",
      "\n",
      "PMI: 8.670392753575022\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "from nltk.book import text4\n",
    "\n",
    "# Print collocation list\n",
    "print(\"Collocation List:\", text4.collocation_list(), \"\\n\")\n",
    "\n",
    "# Select a random collocation from the list\n",
    "random.seed(123456)\n",
    "random_collocation = random.choice(text4.collocation_list())\n",
    "print(\"Random Collocation:\", random_collocation, \"\\n\")\n",
    "\n",
    "# Count total occurences of \"Chief Justice\"\n",
    "chief_count = 0\n",
    "justice_count = 0\n",
    "chief_justice_count = 0\n",
    "\n",
    "for word in text4:\n",
    "    if word.lower() == 'chief':\n",
    "        chief_count += 1\n",
    "    if word.lower() == 'justice':\n",
    "        justice_count += 1\n",
    "\n",
    "chief_justice_count = len(re.findall(\"Chief Justice\", ' '.join(text4)))\n",
    "total_length = len(text4)\n",
    "\n",
    "# Calculate PMI (Point-Wise Mutual Information)\n",
    "pmi = math.log2((chief_justice_count / total_length) / ((chief_count / total_length) * (justice_count / total_length)))\n",
    "print(\"PMI Score:\", pmi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The phrase \"Chief Justice\" has a PMI score of 8.67 which suggests that it is a strong coallocation. The word \"Chief\" is defined as a leader of a clan and the word \"Justice\" is defined as a judge or mastrate. The leader of a clan of judges generally does not make sense in the English language. However, \"Chief Justice\" as a position is well known and understandable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
